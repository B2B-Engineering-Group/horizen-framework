
# Вводный экспресс-курс для разработчика

Мы занимаемся коммерческой разработкой через аутсорсинг, а также специализируемся на автоматизации компаний. Т.е находимся на стыке между разработчиками и представителями организаций (или предпринимателями).

За счет опыта структурирования бизнес-процессов, программной инфраструктуры и методологий управления обеспечиваем комфортные условия работы для обеих сторон с упором на эффективные и надежные решения.

**Пример из жизни разработчика:**
Вы пишете крупный монолитый проект. Постоянно добавляется и меняется функционал. Вы пренебрегаете тестированием. Документация делается руками или не делается вовсе. За счет этого увеличивается связанность и технический долг. Менеджер подгоняет. Множество багов. Вы перегружены, но нет возможности внедрить дополнительного разработчика и выделить задачи с которыми он справится. Сложно прогнозировать дедлайн. С каждой итерацией продукт превращается в клубок. Все зависит от одного человека и даже самые простые изменения могут привести к выходу системы из строя.

**Пример из жизни предпринемателя:**
Вы предпринематель и погрязли в операционной деятельности. Почти все делаете сами, что-то делигируете сотруднику с которым давно работаете. Вы понимаете, что вся деятельность завязана на вашей доступности. Вы не успеваете заниматься стратегией и находитесь в ступоре. Вы подумываете нанять второго себя или многофункционального сотрудника, но осознаете нереальность этой мысли. Любая хорошая идея разбивается о форс-мажоры, на которые необходимо отвлечься. Продажи не растут, есть ощущение что все в любой момент может развалиться.

**В обоих примерах общая ключевая проблема:** высокая связанность и отсутствие системного управления структурой и развитием.

Для решения данной проблемы мы используем HoriZen. Это TDD фреймворк и одноименная методология, основанная на философии Unix. Их сфера применения выходит далеко за рамки разработки программных продуктов и помогает правильно организовать любую комплексную систему, в том числе бизнес-процессы в компаниях наших клиентов.

**Методология базируется на 6 тезисах:**
1. Элемент системы должен делать что-то одно и делать это хорошо.  
2. Элемент системы должен быть настолько прост, насколько это возможно.  
3. Элемент системы должен быть инкапсулированным и конфигурируемым.  
4. Элемент системы должен быть проверяемым и регламентированным.  
5. Элемент системы должен быть горизонтально масштабируемым.  
6. Элементы системы и их кросс-взаимодействия должны быть унифицированы.

В зависимости от уровня абстракции или фокуса элементом системы может быть: компания, должность человека, канал продаж, кластер программных модулей, сам модуль, определенный элемент программного модуля и т.д.

Фреймворк HoriZen написан исходя из этих тезисов и его основная задача - обеспечивать соответствие всех разрабатываемых на нем программных решений этим же тезисам.

В свою очередь, програмнные решения разрабатываются для бизнес-процессов. Если последние соответствуют тезисам то проблемы из примеров остаются далеко позади и гораздо меньше факторов тормозят рост организации.

## Начало работы

Вам необходимо установить фреймворк Hoirzen. В него встроен набор утилит, включающих развертывание шаблонных микросервисов для фронтенда и бэкенда.

```sudo npm install -g git@github.com:B2B-Engineering-Group/horizen-framework.git#master```
```horizen-help //должен выдать маленькую документацию```

Затем установите и запустите mongodb, это можно сделать через Docker.
```docker pull mongodb/mongodb-community-server```
```docker run --name mongo -d mongodb/mongodb-community-server:latest```

Теперь создадим два микросервиса бэкенд и фронтенд. Дважды запустите `horizen-create` и ответьте на вопросы. Утилита инициализирует 2 шаблонных репозитория. 


Откройте два окна терминала, зайдите в эти папки и запустите команды.
```horizen-run server //в бэкенд папке```
```horizen-run dev //в фронтед папке```

Поднимется два сервера. Откройте http://127.0.0.1:3000 в браузере. Если вы увидели большую надпись "Hello World", значит все сконфигурировано правильно. 

Теперь вы можете приступить к изучению документации и разработке.

> (!) Если документации окажется недостаточно, вы всегда можете задать
> вопрос коллегам или самостоятельно изучить фреймворк. Он совсем не
> большой и лежит в папке .horizen-framework. Вносить изменения в этой
> папке нельзя т.к она генерируется автоматически.




## Разбор Back-end концепций

Заходите в папку бэкенда и параллельно с чтением текста ниже, находите описываемые структуры в коде и изучайте. Начнем с ключевых сущностей:

**Процессы** (лежат в ./processes/$name/proccess.js) - это точки запуска. Т.е при вводе команды `horizen-run server` запускается процесс из папки с именем server. С точки зрения терминологии мы делим процессы на два условных типа: *сервер* и *демон*. 

 - Сервер возвращает из функции инициации список API контроллеров и
начинает слушать входящие запросы. Сответственно при необходиомости масштабировать микросервис, запускается несколько одинаковых процессов под балансером Docker Swarm. Если нужно поднять два разных API на базе одной кодовой базы (для разграничения доступов кросс-микросервисного взаимодействия) туда добавляется дополнительный процесс с нужными контроллерами. Процессы такого типа всегда работают в условиях многопоточности.
   
 - Демон не возвращает список API контроллеров и как следствие ничего не слушает. Он спокойно выполняет определенные фоновые процессы (например потоковая обработка объектов из базы данных и т.д). Как правило не масштабируется и всегда работает один поток, либо демон имеет абстаркции на уровне очередей в базе данных чтобы делать вычисления в кластере.

Процессы обычно маленькие (50-100 строк кода), их задача именно инициализировать все остальные сущности (сервисы и контроллеры). Рядом с файлом process.js всегда есть файл test.js. Он нужен для e2e тестирования (т.е выполнения запросов к API эмулируя клиент).

-----

**API Контроллеры** (лежат в ./controllers/$Name.js)

При инициализации фреймворка они автоматически подтягиваются из папки и передаются как параметр в коллбэк внутри процесса. Т.е контроллеры которые вы возвращаете в коллбэке инициализации начнут обрабатывать запросы по укзанному ендпойнту.  

Построчно розберем универсальную схему контроллера:

```
//db, initiatedService - переданные вами зависимости (локальные и общие сервисы)
export default function({db, initiatedService}){
	return {
		endpoint: "/api/getHello",//Путь на котором слушает контроллер
		auth: "bypass",//Тип проверки доступа
		description: "",//Описание для документации
		errors: {
			name: "Какой-то текст"//Декларация кастомной ошибки
		},
		
		//Схема запроса
		reqSchema: ({string, object, array, number, any}, {})=> ({
			example: string(/.{1,100}/),
		}),

		//Схема ответа
		resSchema: ({string, object, array, number, any}, {})=> ({
			text: string(/.{1,100}/)
		}),

		//Что именно делает контроллер при поступлении запроса
		controller: async function({body, auth}){
			//throw new Error("name");//пример вызова ошибки
			return {text: "Hello world! " + body.example}//это будет отправлено в ответе на запрос
		}
	}
}
```


**Подробнее про свойство `auth`  (тип проверки доступа):**

По умолчанию каждый микросервис интегрируются в нашу инфраструктуру. В ней уже есть набор микросервисов отвечающий за идентификацию/аутентификацию и авторизацию запросов, а также за конфигурацию этих параметров. Поэтому при поступлении любого запроса на указанный API, фреймворк сам проверит есть ли доступ у пользователя (или другого микросервиса) на этот запрос. Вам не требуется думать про это глобально, достаточно определить какой тип авторизации вам нужен для каждого контроллера в зависимости от его цели, все остальное будет сделано за вас. 

Поддерживаемые типы:
1) `bypass` - означает что это публичный контроллер. Никаких проверок нет.
2) `authorized` - для авторизованных пользователей и микросервисов.
3) `authorized:user` - только для авторизованных пользователей
4) `auhtorized:app` - только для авторизованных микросервисов

В пунктах подразумевающих авторизацию, при исполнении контроллера вы получите одноименный объект `auth`, содержащий `{userId: INT}` или `{appId: INT}`. 

Реальный пример работы:
Пользователь на фронтенде жмет на кнопку и происходит API запрос. Фреймворк запускает внутренние механизмы проверки токена из заголовков запроса и в случае успеха выполняет код внутри метода controller. Если пользователь не авторизован то сообщается специальный код ошибки, который ловится фреймворком на фронтенде и редиректит пользователя на oAuth страницу входа (если не аутентифицирован) или на страницу 403 ошибки.


**Подробнее про `reqSchema` и `resSchema`**

Весь фреймворк HoriZen построен на принципах жесткой типизации на уровне API. Мы не используем TypeScript или Mongoose, но делаем упор именно на типизацию при кросс-микросервисных взаимодействиях. 

Каждый контроллер может отправлять только JSON или файлы, и принимать может только JSON (Query параметры для GET  транслируются в JSON) или файлы. При каждом запросе внутренний валидатор фреймворка проверяет параметры запроса на соответствие `reqSchema` и если в нем не хватает параметров или параметры невалидны или у них другие типы - возвращает ошибку валидации и не запускает функцию контроллера.  `resSchema` - это то же самое, но для ответов контроллера. Если контроллер пытается отправить что-то не соответствующее декларации ответа то весь процесс упадет с ошибкой.

Такой контроль над точками входа и выхода позволяет автоматически гененрировать документацию по всему микросервису. А также проводить предиктивное интеграционное тестирование (специальный микросервис обнаруживает коллизии в документации и проверяет встанет кубик в пазл или нет).

В процессе работы контроллера там могут происходить ошибки. Любая ошибка возвращает статус запроса 200 и JSON с описанием и кодом этой ошибки в теле ответа. Если код ошибки задекларирован то будет отправлен он, иначе стандартный JSON с кодом 500 и описанием "Internal server error".

Помимо контроллеров которые лежат в папке `controllers` и определяют API самого микросервиса. Существуют подобная декларация для запросов к API внешних микросервисов из исхоного, подробнее она прописана в пункте *кросс-микросервисное взаимодействие*.

Тестирование вызовов контроллеров обязательно и происходит через e2e процесса. Как правило контроллеры очень маленькие и мы стремимся замыкать всю основную логику на сервисы передаваемые через зависимости.


---
**Сервисы** (лежат в ./services/$Name/service.js)

Это оплот всей логики приложения. Каждый сервис представляет из себя функцию-конструктор отвечающую за определенную сущность, которая принимает параметры в виде других сервисов и предоставляет набор методов. Каждый сервис реализует полиморфизм за счет внутренних провайдеров. Сервисы и вся система наследования спроектированы так, чтобы их легко можно было разрабатывать через Unit тесты. Они прописываются в файле test.js внутри папки конкретного сервиса.

**Разобрать  сервис на примере всего приложения:**

Предположим у вас есть задача. Сделать микросервис который позволяет инициализировать форму оплаты в банке по POST запросу из CRM, который содержит идентификатор банка и счета, который необходимо оплатить. 

Правильно поступить следующим образом:

1) Делаем 2 контроллера `initOrder` и `getOrderStatus`
2) Делаем сервис `BankManager`, а внутри него папку `providers` с нужными банками например (`SberBank.js`, `AlfaBank.js`), всю общую логику выносим в `Service.js` а индивидуальную инкапсулируем по провайдерам.
3) Внутри процесса инициализируем сервис и передаем его как зависимость контроллерам.
4) `initOrder` будет принимать номер счета из CRM и тип банка в API запросе, его задача в основном валидация, он вызовет одноименный метод сервиса `initOrder` и передаст туда  данные из body (тела запроса). 
5) На базе параметров `initOrder` определит какой провайдер должен обратиться по API к банку и поручит это дело ему. Затем сохранит результат в унифицированном виде в базе данных.
7) Делаем дополнительный демон-процесс, который по каждой активной транзакции будет обновлять статус в базе данных.
6) При запросе, `getOrderStatus` будет вызывать функцию из сервиса для получения статуса и возвращать его в ответе.

Естественно все методы сервиса вы пишутся через Unit тесты, включая изолированную проверку провайдеров. Такой микросервис может масштабироваться относительно бизнес задач и туда можно легко добавить больше банков. 

Такой подход с провайдерами, в рамках внутренней терминологии мы называем выводом чего-то в горизонталь (т.е горизонтальное масштабирование). Мы используем его повсеместно не только в сервисах, а вообще везде где требуется заложить возможность расширения определенной сущности новыми однотипными провайдерами.

Сервисы используются в микросервисах любых типов и бэкенд и фронтенд.


----
**Кросс-микросервисное взаимодействие**

Большинство микросервисов не работает само по себе. Они делают API запросы к другим. Запросы можно условно разделить на две зоны: 

**[High-Risk]** Внешние API, которые не являются частью нашей инфраструктуры, это заведомо означает, что они шакальные и доверия к ним ноль. Они могут быть относительно надежными, например как API яндекса, а могут постоянно ломаться как Bitrix24 или иметь ограничения. Поэтому есть два способа взаимодействия с ними: 

Если внешний API с которым вы работаете является незначительным. Например обогащает какие-то данные и не нужен нигде кроме микросервиса который вы разрабатываете то к нему можно делать прямой `fetch`, но необходимо заранее предусмотреть, что он может упасть или вернуть другой формат данных. Вы должны заложить абстракции, которые помогут команде поддержки узнать об этом.

Если внешний API является значительным, т.е вы делаете много разных запросов к нему и возможно другие микросервисы тоже их делают, либо он требует дополнительной авторизации то он становится потенциальной дырой в безопасности и надежности. Поэтому, как правило, мы реализуем отдельный микросервис обеспечивающий сахар над внешним API, увеличивающий его стабильность и добавляющий документацию на базе наших механизмов.

**[Low-Risk]** API микросервисов в рамках нашей сосбственной инфраструктуры. Они все написаны на Horizen и все имеют единое поведение. Поэтому мы всегда знаем, что микросервис либо работает либо нет. Для того чтобы упростить приемочное и интеграционное тестирование при работе с пулом микросервисов Horizen обеспечивает все необходимое через обвязку над `fetch`.

При инициализации фреймворка в коллбэк помимо общих сервисов передается объект options. В нем есть набор методов для настройки хорайзена. Один из методов позволяет декларировать внешние API методы которые использует модуль.

```
options.addRemoteAPI("exchangeToken", {
	method: "POST",//метод запроса
	microservice: "auth_api",//имя микросервиса в пуле
	endpoint: "/api/getCodeByToken",//путь к контроллеру
	reqSchema: ({string}, {})=> ({//схема запроса
		api_key: string(/.{1,100}/),
		token: string(/.{1,100}/)
	}),	

	resSchema: ({string})=> ({//схема ответа (работает как $project в mongodb)
		code: string(/.{1,100}/)
	})
});
```

После декларации можно где угодно и сколько угодно делать запросы на данный API:
 
```const result = await api.exchangeToken({...body}) //Пример запроса```

По аналогии с контроллером в декларации заполняется куда может слать запросы микросервис, что он отправляет и что ожидает в ответе. Но в данном случае нет необходимости прописывать все поля ответа, достаточно прописать лишь те, которые требуются. Если нужных полей не будет, но при этом не произошло ошибки - микросервис упадет. Благодаря подобной декларации мы еще до деплоя можем автоматически установить все кросс-взаимосвязи и провести интеграционное тестирование. 


----
**Работа с типами (валидатор)**

Все схемы запросов/ответов указываются в едином формате. Есть базовые типы и кастомные типы. Базовые типы доступны сразу и передаются в первом параметре функции. Кастомные типы (их делаете вы для высокоуровневых моделей) передаются во втором параметре.

```
//Для JSON 
({string, number, boolean, array, object, any}, {anyString})=> ({
	message: string(/.{1,100}/).optional() //Любая строка длиной от 1 до 100 символов
	users: array(object({//Массив объектов длиной от 1 до 10
		userId: anyString(),//кастомный тип
		name: string(/.{1,100}/)
	})).length(1, 10)
}),	

//Для файлов
({file}, {})=> (file({
	maxSizeMb: 1, 
	mimetypes: ["*"]
})	
```

Модели кастомных типов создаются через специальный метод, передаваемый при инициализации фреймворка. Рекомендуется выделять модели в отдельный сервис.

```
options.setCustomTypes(({string, number}) => ({
	anyString: ()=> string(/.{0,150}/)
}));
```

У валидатора есть определенные ограничения. Объекты не могут иметь динамичные поля. Корневая сущность это всегда объект, либо file. Подобные ограничения необходимы для корректной работы системы интеграционного тестирования, они редко доставляют дискомфорт, но иногда приходится дольше думать над архитектурой чтобы учесть эти особенности.

> (!) Тип any() преимущественно используется для этапов разработки, пока модель данных находится в процессе изменения. Использовать его в продакшене можно только в исключительных случаях по согласованию с системным архитектором. Не смотря на то, что он присутствует даже в корневых методах фреймворка, любое использование any() является черным ящиком на этапе интеграции.

----
**Работа с файлами**

Вся работа с файлами унифицирвана с помощью внутренних механизмов фреймворка. 

Например, чтобы получить файл в контроллере вы просто устанавливаете в `reqSchema` соответствующий тип. Внутренние механизмы сами обработают `multipart/form-data` и вызовут контроллер в котором `body` будет иметь следующий вид: `{blob, filename}`. Из блоба вы всегда можете получить `mime` и размер файла, а `filename` представляет из себя оригинальное название у пользователя. По аналогии, чтобы отправить файл в ответе контроллера, необходимо вернуть объект вида `{blob, filename}` и указать тип `file` в `resSchema`.

Отправка/загрузка файлов с одного микросервиса на другой работает по такому же принципу через сервис `api`. Также в сервисе `gfs`, который передается при инициализации фреймворка есть набор функций для удобного сохранения и выгрузки файлов из базы данных (GridFs) по тому же принципу. 

К сожалению данная редакция фреймворка не поддерживает потоки на стыках между микросервисами и файлы всегда выгружаются в опреативную память целиком. В будущих редакциях мы добавим подобный функционал, если это потребуется относительно бизнес-задач (например разработка стриминговой платформы).



## Разбор Front-end концепций

Фронт представляет из себя чистую сборку TailwindCss + React + NextJs. Как работать с этими технологиями вы можете найти в официальной документации. 

Немногочисленные дополнения с нашей стороны: 

1) Сахар над запросами к API микросервисов на базе Horizen с поддержкой oAuth
2) Наличие папки services в такой же структуре как на бэкенде с возможностью Unit тестирования тем же механизмом.
3) Набор утилит для развертывания и запуска по аналогии с бэкендом (унификация утилит)

**Как делать запросы к API**

```
import {api} from 'horizen-framework/frontend';

const result = await api.call("getHello", {
    auth: false,
    params: {}
});
```

Декларировать что-либо как на бэкенде не требуется. Функция запроса сама подставит токен доступа в нужное место если пользователь аутентифицирован. Если бэкенд сообщит ошибку доступа, то эта же функция произведет редирект на указанные в конфигурации ссылки. Сервис `api` самостоятельно получит токен доступа после возврата с oAuth. Грубо говоря вам ни о чем не нужно думать, просто делаете запросы к апи через функцию выше.

Тестировать на фронтенде нужно только сервисы, также через юниты. Визуальные компоненты мы не тестируем, они на совести у разработчика.


## Про конфигурационные файлы

И в бэкенд и в фронтед микросервисах есть файл config.json. Все что должно отличаться на продакшене и во время разработки конфигурируюется в нем. В том числе изначальные параметры фреймворка. То же самое касается файла Dockerfile, он необходим для сборки контенейра в цикле CI/CD и продакшена.


## Про тестирование

Вы можете запустить тесты и на бэкенде и на фронтенде командой `horizen-tester`. Она запустит как юниты так и e2e тесты ( все, во всех папках). e2e требуют запущенные процессы, вы можете запустить их самостоятельно или импортировать процесс в соответствующий тест, но это смешает логи тестов и процесса.



## Про приемку задач

После того как вы завершили работу, запушили код в репозиторий и пометили задачу как готово. Ваш модуль будет отправлен на приемочное тестирование. 

Во время проверки будет автоматически проанализировано покрытие тестами, работоспособность тестов, а также проверена интеграционная составляющая через сопоставления схем документации вашего микросервиса с теми микросервисами, от которых он зависит. 

Если автоматическое тестирование прошло, в дело вступает системный архитектор и проводит ревью кода. Он определяет, что вы написали все так как нужно с точки зрения бизнес-задач и потеницального масштабирования, не использовали тип валидатора any() для продакшена и правильно сделали тесты. Если все хорошо, задача принимается.